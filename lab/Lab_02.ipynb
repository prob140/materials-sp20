{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\" style=\"border-style: hidden\" class=\"table\"> <tr><td class=\"col-md-2\"><img style=\"float\" src=\"http://prob140.org/assets/icon256.png\" alt=\"Prob140 Logo\" style=\"width: 120px;\"/></td><td><div align=\"left\"><h3 style=\"margin-top: 0;\">Probability for Data Science</h3><h4 style=\"margin-top: 20px;\">UC Berkeley, Fall 2019</h4><p>Ani Adhikari and Jim Pitman</p>CC BY-NC 4.0</div></td></tr></table><!-- not in pdf -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "# SETUP\n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "from prob140 import *\n",
    "\n",
    "# These lines do some fancy plotting magic\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# These lines make warnings look nicer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "\n",
    "# Useful for probability calculations\n",
    "from scipy import stats\n",
    "from scipy import special\n",
    "\n",
    "# Imports for interactive widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Lab Resources\n",
    "\n",
    "* [`prob 140` Library Documentation](http://prob140.org/prob140/)\n",
    "* [`datascience` Library Documentation](http://data8.org/datascience/)\n",
    "* [Prob 140 Code Reference Sheet](http://prob140.org/assets/prob140_code_reference.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "# Lab 2: Total Variation #\n",
    "\n",
    "In Data 8, you measured the difference between two categorical distributions by calculating the total variation distance between them. In this lab, you will start by interpreting the total variation distance (TVD) in terms of probabilities. You will then use total variation distance to measure the difference between two probability distributions on the non-negative integers. \n",
    "\n",
    "This will give you a way to quantify how well one distribution approximates another. \n",
    "\n",
    "The focus will be on Poisson distributions, which are often used as approximations to distributions of counts of rare events. In particular, the Poisson $(1)$ distribution approximates the distributions of some random counts that have $1$ as their most likely value.\n",
    "\n",
    "A random variable $X$ has the Poisson $(1)$ distribution if\n",
    "\n",
    "$$\n",
    "P(X = k) ~ = ~ e^{-1} \\frac{1}{k!}, ~~~ k \\ge 0\n",
    "$$\n",
    "\n",
    "This is a probability distribution on infinitely many possible values. We will need that infinite support if we are going to approximate distributions on the values $0, 1, 2, \\ldots, n$ for arbitrarily large $n$.\n",
    "\n",
    "In class we are studying two situations in which probabilities approach those in a Poisson distribution. One is counting the number of matches the matching problem with $n$ letters, when $n$ is large. The other is counting the number of successes in $n$ i.i.d. Bernoulli $(p)$ trials, for large $n$ and small $p$.\n",
    "\n",
    "In this lab you will look at the entire distribution of the number of matches, and also the binomial $(n, 1/n)$ distribution. You will compare them with their Poisson $(1)$ approximations, both visually and also by a numerical measure of the distance between two distributions. In doing so, you will find an upper bound for the amount of error when you use the approximations to calculate probabilities.\n",
    "\n",
    "What you will learn:\n",
    "- The definition of total variation distance (TVD) and its interpretation in terms of the amount of error in approximating probabilities\n",
    "- The computation of the exact distribution of the number of fixed points (matches) of a random permutation of $n$ letters\n",
    "- For large $n$, properties of the TVD between the distribution of the number of matches and the Poisson $(1)$ distribution\n",
    "- For large $n$, properties of the TVD between the binomial $(n, 1/n)$ and Poisson $(1)$ distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Instructions\n",
    "Your labs have two components: a written portion and a portion that also involves code. Written work should be completed on paper, and coding questions should be done in the notebook. You are welcome to LaTeX your answers to the written portions, but staff will not be able to assist you with LaTeX related issues. It is your responsibility to ensure that both components of the lab are submitted completely and properly to Gradescope. Refer to the bottom of the notebook for submission instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 1: Total Variation Distance ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Suppose you have two probability distributions on the same set of possible values $x_1, x_2, \\ldots , x_n$. Let the two distributions be $b_1, b_2, \\ldots, b_n$ and $g_1, g_2, \\ldots, g_n$, where for each $i$ the $b$-distribution assigns probability $b_i$ to the value $x_i$ and the $g$-distribution assigns probability $g_i$.\n",
    "\n",
    "The *total variation distance* between the two distributions is defined by\n",
    "\n",
    "$$\n",
    "tvd(b, g) = \n",
    "\\frac{1}{2} \\sum_{i=1}^n |b_i - g_i| \n",
    "$$\n",
    "\n",
    "The choice of notation comes from the blue and gold colors you will see in overlaid histograms below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 1a) [CODE] Computing TVD ###\n",
    "Define a function `tvd` that takes two probability arrays as arguments and returns the total variation distance between them. You should just assume that both of the input arrays will be probability distributions. You don't have to include code to check that each array is non-negative and sums to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def tvd(b, g):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "When the two arrays are $b = [0.4, 0.3, 0.2, 0.1]$ and $g = [0.25, 0.35, 0.25, 0.15]$, the histograms look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "b = make_array(0.4, 0.3, 0.2, 0.1)\n",
    "g = make_array(0.25, 0.35, 0.25, 0.15)\n",
    "\n",
    "k = np.arange(4)\n",
    "\n",
    "blue_dist = Table().values(k).probabilities(b)\n",
    "gold_dist = Table().values(k).probabilities(g)\n",
    "\n",
    "Plots('Distribution 1', blue_dist, 'Distribution 2', gold_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Calculate the TVD by mental math. Then run the cell below to confirm that your function `tvd` is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "tvd(b, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The total variation distance between the two distributions is the total amount by which the areas of the blue bars exceed those of the corresponding gold bars. That's exactly equal to the total amount by which the gold bars exceed the blue.\n",
    "\n",
    "This is almost apparent from the definition of total variation distance, and you will prove it in homework. Just assume it for now as you did in Data 8. It is an intuitively reasonable measure of the difference between the two distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 1b) Another Way of Interpreting TVD ###\n",
    "\n",
    "**This part will be done in section on Wednesday; don't include it in your Gradescope submission.**\n",
    "\n",
    "Thus far, our interpretation of total variation distance has been essentially geometric: the amount by which the blue bars exceed the gold. There is an equivalent interpretation in terms of probabilities that makes it easier to understand what the numerical value of the distance is telling us.\n",
    "\n",
    "Suppose you have a finite set of possible values, and a choice of two probability distributions to use for finding probabilities. For example, the choices might be the exact distribution of a random variable and an approximate distribution. \n",
    "\n",
    "**The total variation distance between the two distributions is the biggest difference you can possibly get if you compute the probability of an event using each of the two distributions.**\n",
    "\n",
    "Formally, if $S$ is the space of all possible values, then the total variation distance between the blue and gold distributions is equal to\n",
    "\n",
    "$$\n",
    "\\max\\{ \\big{\\lvert} P_{blue}(A) - P_{gold}(A) \\big{\\rvert} : A \\subseteq S\\}\n",
    "$$\n",
    "\n",
    "This can be shown in a few straightforward steps and you will do that in homework. For now, confirm that it is true for the distributions in **1a**, in the following steps.\n",
    "\n",
    "- Figure out how many events can be created out of the outcomes $\\{0, 1, 2, 3\\}$.\n",
    "- List all the events.\n",
    "- For each event, compute the absolute difference between the blue and gold probabilities of the event. Your goal is to find the biggest possible absolute difference, so you might not even need to compute each one.\n",
    "- See which event or events correspond to the biggest absolute difference, and compare the value of that absolute difference with the TVD that you computed in **1a**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 2: Fixed Points of a Random Permutation ##\n",
    "\n",
    "Let $M_n$ be the number of fixed points in a random permutation of the values $1, 2, 3, \\ldots, n$. You can think of $M_n$ as the number of matches when $n$ letters labeled $1$ through $n$ are permuted randomly into $n$ envelopes labeled $1$ through $n$.\n",
    "\n",
    "[Recall](http://prob140.org/textbook/Chapter_05/03_The_Matching_Problem.html) that the distribution of $M$ is given by \n",
    "\n",
    "$$\n",
    "P(M_n = k) ~ = ~ \n",
    "\\frac{1}{k!} \\cdot \\big{(} 1 - \\frac{1}{1!} + \\frac{1}{2!} - \\frac{1}{3!} + \\cdots (-1)^{n-k}\\frac{1}{(n-k)!} \\big{)} \\\\\n",
    "$$\n",
    "for $0 \\le k \\le n$.\n",
    "\n",
    "Also, if $n$ is large, recall that for each fixed $k$ we have the approximation \n",
    "\n",
    "$$\n",
    "P(M_n = k) ~ \\approx ~ \\frac{e^{-1}}{k!}\n",
    "$$ \n",
    "\n",
    "These are the terms in the Poisson $(1)$ distribution.\n",
    "\n",
    "In this part of the lab you will compare the distribution of $M_n$ with its Poisson $(1)$ approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2a) [CODE] Computing $P(M_n = k)$ ###\n",
    "Complete the definition of the function `prob_matches` that takes $k$ and $n$ as its arguments and returns $P(M_n = k)$. Use as many lines of code as you need.\n",
    "\n",
    "Use array operations. The `special` module of SciPy has been imported and contains a useful `factorial` method: \n",
    "\n",
    "`special.factorial(integer_array)` evaluates to an array consisting of the factorials of all the integers in `integer_array`.\n",
    "\n",
    "Be careful about signs. Follow the lead of the code provided, and tackle all the positive terms separately from all the negative terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def prob_matches(k, n):\n",
    "    x_even = np.arange(0, n - k + 1, 2)\n",
    "    x_odd = np.arange(1, n - k + 1, 2)\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "To confirm that your function is working correctly, think about what $P(M_n = n-1)$ should be, and then run the cell below to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "prob_matches(99, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Use the formula for $P(M_n = k)$ to explain why $P(M_n = 0)$ is very close to $P(M_n = 1)$ when $n$ is large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Now run the cell below and confirm that your function is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "prob_matches(0, 100), prob_matches(1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2b) [CODE] The Bulk of the Distribution ###\n",
    "Use `prob_matches` to define a function `match_dist` that takes $n$ as its argument and returns an array consisting of the probabilities $P(M_n = k)$ for $0 \\le k \\le n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def match_dist(...):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The expression `match_dist(100)[0:11]` evaluates to an array consisting of the elements 0 through 10 of the array `match_dist(100)`. \n",
    "\n",
    "Explain what the output of the cell below tells you about the distribution of $M_n$. As with most questions about random variables, start by thinking about the possible values of $M_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "sum(match_dist(100)[0:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 2c) [CODE] Visualization ###\n",
    "Plot the distribution of $M_{100}$, the number of matches in the matching problem with 100 letters. Use `Plot(dist)` where `dist` is a distribution object created by either:\n",
    "\n",
    "`Table().values(array_of_values).probabilities(array_of_probabilities)`\n",
    "\n",
    "or\n",
    "\n",
    "`Table().values(array_of_values).probability_function(name_of_function)` where `name_of_function` takes a possible value as its argument and returns the probability of that value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "k = np.arange(11)\n",
    "\n",
    "...\n",
    "\n",
    "matches_100 = Table().values(k)...\n",
    "Plot(matches_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 3: Poisson Approximation to the Matching Distribution ##\n",
    "\n",
    "Recall from the introduction to the lab that $X$ has the Poisson distribution with parameter 1 if \n",
    "\n",
    "$$\n",
    "P(X = k) ~ = ~ e^{-1} \\frac{1}{k!}, ~~~ k \\ge 0\n",
    "$$\n",
    "\n",
    "The `stats` module of SciPy can be used to calculate the probabilities in this distribution. If `values` is an array of non-negative integers, then\n",
    "\n",
    "`stats.poisson.pmf(values, 1)`\n",
    "\n",
    "evaluates to an array of probabilities of the entries in `values`, determined by the Poisson $(1)$ formula above.\n",
    "\n",
    "The acronym `pmf` stands for \"probability mass function\". It is common for probabilists to think of the probabilities in the distribution of a discrete random variable as masses attached to the random variable's possible values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 3a) [CODE] The Poisson $(1)$ Distribution ###\n",
    "Draw a histogram of the Poisson $(1)$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "k = np.arange(11)        # selected possible values\n",
    "poisson_1_probs = ...    # array of corresponding Poisson (1) probabilities\n",
    "poisson_1_dist = ...\n",
    "Plot(poisson_1_dist)\n",
    "plt.title('Poisson (1) Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Notice:\n",
    "\n",
    "- The distribution has two modes, at 0 and 1. In exercises you will see why.\n",
    "- Though there are infinitely many possible values, the set of *probable* values is very small — there is hardly any probability visible beyond the value 4.\n",
    "- The distribution is extremely similar to the distribution of the number of matches in **2c**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 3b) [CODE] TVD Between the Matching Distribution and its Poisson Approximation ###\n",
    "Use the `stats` module and functions you have already defined in this lab to define a new function `matches_Poisson_tvd` that takes $n$ as its argument and returns the total variation distance between the distribution of the number of matches $M_n$ and the Poisson $(1)$ distribution.\n",
    "\n",
    "Though the Poisson distribution has infinite support, you have seen that almost all of the probability is concentrated on just a few small values. So it's fine to compute the Poisson $(1)$ probabilities only for $0, 1, 2, \\ldots, n$, the possible numbers of matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def matches_Poisson_tvd(n):\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "To see if the value that your function is returning make sense, start by looking at the distribution of $M_5$, the number of matches if you just have 5 letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "matches_5 = Table().values(np.arange(6)).probabilities(match_dist(5))\n",
    "Plot(matches_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Which do you think should be larger: `matches_Poisson_tvd(5)` or `matches_Poisson_tvd(100)`? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Run the cell below to see that your function behaves consistently with your answer above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "matches_Poisson_tvd(5), matches_Poisson_tvd(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 3d) [CODE] Error in the Approximation ###\n",
    "Let $a$ and $b$ be two integers with $0 \\le a < b \\le 100$. Suppose you approximate $P(a \\le M_{100} \\le b)$ by $\\sum_{k=a}^b e^{-1}\\frac{1}{k!}$. What is the largest possible error you could make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The more letters you have, the better the approximation will be. To visualize this, extend `tvd_table` below with a column labeled `Matches (n)` that contains the total variation distance between the exact distribution of the number of matches and its Poisson $(1)$ approximation. In each row, the number of letters $n$ is given by the entry in Column 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "tvd_table = Table().with_column('n', np.arange(5, 101))\n",
    "\n",
    "matches_tvds = tvd_table...\n",
    "\n",
    "tvd_table = tvd_table...\n",
    "\n",
    "tvd_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Use the `Table` method `plot` to draw a line plot of the TVDs as a function of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "plt.title('TVD between Binomial (n, 1/n) and Poisson (1)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Note how sharply the graph falls. For $n \\ge 10$ or so, there is almost no error at all in using the Poisson $(1)$ distribution to approximate the distribution of $M_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "#newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Part 4. Poisson $(1)$ Approximation to Binomial Distributions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Roughly stated, a theorem we proved in class says that if $n$ is large and $p$ is small, then the binomial $(n, p)$ probabilities are close to Poisson $(np)$ probabilities. \n",
    "\n",
    "Therefore, for large $n$ binomial $(n, 1/n)$ probabilities should be close to Poisson $(1)$ probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 4a) [CODE] Binomial $(10, 1/10)$ Distribution ###\n",
    "If `values` is an array of integers in the range 0 through $n$, then\n",
    "\n",
    "`stats.binom.pmf(values, n, p)`\n",
    "\n",
    "evaluates to an array of the binomial $(n, p)$ probabilities of the entries in `values`.\n",
    "\n",
    "Display a histogram of the binomial $(10, 1/10)$ distribution. Notice how the probabilities are concentrated on the low values. This is a signal to start thinking about Poisson approximations, even though the number of trials ($n = 10$) isn't very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "# binomial (n, 1/n) distribution\n",
    "n = 10                             # number of trials\n",
    "\n",
    "k = ...                            # possible values\n",
    "binom_probs = ...                  # binomial (n, 1/n) probabilities\n",
    "\n",
    "\n",
    "binom_dist = ...\n",
    "\n",
    "Plot(binom_dist)\n",
    "plt.title('Binomial (10, 1/10) Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Since $n = 10$ isn't very large, this distribution doesn't look exactly like the Poisson $(1)$ distribution though the two have many similarities. Run the cell below to see the overlaid histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "outputs": [],
   "source": [
    "poisson_1_probs = stats.poisson.pmf(k, 1)\n",
    "poisson_1_dist = Table().values(k).probabilities(poisson_1_probs)\n",
    "\n",
    "Plots('Binomial (10, 1/10)', binom_dist, 'Poisson (1)', poisson_1_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "At this point it will come as no surprise that the Poisson $(1)$ approximation gets better as $n$ increases. You will quantify this in the remaining exercises below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 4b) [CODE] TVD between the Binomial $(n, 1/n)$ Distribution and its Poisson Approximation ###\n",
    "Define a function `binomial_Poisson_tvd` that takes $n$ as its argument and returns the total variation distance between the binomial $(n, 1/n)$ and Poisson $(1)$ distributions. As before, it's fine to compute the Poisson $(1)$ probabilities only on 0 through $n$, the possible values of the binomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "def binomial_Poisson_tvd(n):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "As a check to see if your function is working correctly, run the cell below. The output should be about $1$%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "binomial_Poisson_tvd(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "### 4c) [CODE] Error in Approximation ###\n",
    "Extend `tvd_table` defined earlier with a column labeled `'Binomial (n, 1/n)'` that contains the TVD between the binomial $(n, 1/n)$ and Poisson $(1)$ distributions, where in each row $n$ is given by the entry in Column 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "binom_tvds = tvd_table...\n",
    "\n",
    "tvd_table = tvd_table...\n",
    "\n",
    "tvd_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Run the cell below to get overlaid line plots of the two TVD columns as functions of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "tvd_table.plot(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "The graph of the binomial-Poisson TVDs drops sharply, though not as sharply as the matches-Poisson TVD graph. \n",
    "\n",
    "Fill in the blanks (use the code cell below if you need to):\n",
    "\n",
    "For values of $n$ that are about $\\underline{~~~~~~~~~~~~~~~~}$ or more, Poisson $(1)$ approximations to binomial $(n, 1/n)$ probabilities will be off by at most 0.5%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "source": [
    "\n",
    "**Your answer here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "Now you can use total variation distance to help answer the question, \"How large does $n$ have to be before I can use the Poisson $(1)$ approximation to the binomial $(n, 1/n)$ distribution?\" \n",
    "\n",
    "- First decide how much error you are prepared to tolerate in your approximations. \n",
    "- Then use `tvd_table` (or an extended one with larger values of $n$) to find the smallest $n$ for which the TVD is below your threshold error. \n",
    "- For that $n$ or larger, the error in your Poisson $(1)$ probability approximations will be below your threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Conclusion ##\n",
    "What you have learned in this lab:\n",
    "- If you use an approximation to the distribution of $X$, then the total variation distance between the exact and approximate distributions measures the worst error you can make in approximating probabilities of events determined by $X$. You didn't prove that in the lab but you will for homeowrk.\n",
    "- The total variation distance between the distribution of the number of matches in a random permutation of $n$ elements and its Poisson $(1)$ approximation falls very sharply. By about 10 elements or so, you might as well use the Poisson distribution for the number of matches.\n",
    "- The total variation distance between the binomial $(n, 1/n)$ and Poisson $(1)$ distributions falls sharply as a function of $n$ and is below 1% even for moderate values of $n$.\n",
    "- Many random variables in this lab have a large number of possible values, and the approximating Poisson distribution has infinitely many possible values. But no matter how large $n$ is, the *probable* values of all the variables are in a very small range — 0 through about 8 or 10 — because all of the distributions are roughly Poisson $(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "#solution": false,
    "#staff": false,
    "#student": false
   },
   "source": [
    "## Submission Instructions ##\n",
    "\n",
    "Many assignments throughout the course will have a written portion and a code portion. Please follow the directions below to properly submit both portions. \n",
    "\n",
    "### Written Portion ###\n",
    "*  Scan all the pages into a PDF. You can use any scanner or mobile application. There are many free apps available that allow you to convert your work into PDFs from your phone. Please **DO NOT** simply take pictures using your phone. \n",
    "* Please start a new page for each question. If you have already written multiple questions on the same page, you can crop the image or fold your page over (the old-fashioned way). This helps expedite grading.\n",
    "* It is your responsibility to check that all the work on all the scanned pages is legible.\n",
    "\n",
    "### Code Portion ###\n",
    "* Save your notebook using File > Save and Checkpoint.\n",
    "* Generate a PDF file using File > Download as > PDF via LaTeX. This might take a few seconds and will automatically download a PDF version of this notebook.\n",
    "    * If you have issues, please make a follow-up post on the general Lab 2 Piazza thread.\n",
    "    \n",
    "### Submitting ###\n",
    "* Combine the PDFs from the written and code portions into one PDF.  [Here](https://smallpdf.com/merge-pdf) is a useful tool for doing so. \n",
    "* Submit the assignment to Lab 2 on Gradescope. \n",
    "* **Make sure to assign each page of your pdf to the correct question.**\n",
    "* **It is your responsibility to verify that all of your work shows up in your final PDF submission.**\n",
    "\n",
    "If you have questions about scanning or uploading your work, please refer to this [guide](https://piazza.com/class/k5cqg51q5qb11v?cid=15) on Piazza or post a follow-up to the thread. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "checksums": [
   "1ccfeeb045915fb7127619e3ebb3482e",
   "19278b3cf9bcdf181f8d11368e62ee13",
   "bbbd0bf658428e10cbfd889247879924",
   "dda24b49941d07a123ae5244852db6d8",
   "518c84f8a1f148dbd174743a2ce02a06",
   "215ed6c8654224bcdb429ca58d5e7135",
   "4fb206b23cca8f1941265599b0f0f320",
   "cc673e0dfad1f3527f5e53fee9d4b00c",
   "b182444b425e530aebac0b1429b8d999",
   "c58db66b6fee81063dd7637932e6e637",
   "8d31345e276966579a2701d3c436204e",
   "dc8bbeae78e29542dbc5821cbfe3e544",
   "05b6c4f7180c1a2613cba1b9916e62c6",
   "f2d3986dda5745b05e14aaacad5637bd",
   "a3953aad6908aff902c86cb74782877c",
   "640061103a186fd26f59746dd4d6de57",
   "2eb2cc1aed68b29173523bf369c0a276",
   "1afa43ff627a216b14f247dfca4c51d6",
   "b9c4afd0d6308b642b09aa30c7aac726",
   "61eabfbb6c12528de4cb52a76fa50a81",
   "1c9082e82d8238d32d369f3533ca5e8c",
   "1dfb51cb71d2f70285237eea8507884f",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "bf1f7cacc1f8f52a58a3967f91a19f66",
   "b9b9cba3588e3769333618b5f4f304d6",
   "ef6ffe53b34e7f709afb7097e7911b96",
   "67103cc9f45ab2bad10bf4cc85d65d19",
   "07e8aa5e3271f9eeabea10bf1d87d8fd",
   "25df0da9d04ff98129e0a93242a87af4",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "1aabb21d7cc08586d33f6f3562958996",
   "341062640dfbd339294b11cd1448f3d4",
   "640061103a186fd26f59746dd4d6de57",
   "42083454535fdc3249d3e08b7701b322",
   "6891bcdabd7c4df54746baf6abb748c5",
   "17c82d80cd605f89249c1a4dcaa6cf5d",
   "ccd968724b42bfca21602c4b01fe670e",
   "a69f522a6aaff30f0c94bb6718e0f0a6",
   "ebe5b742470b60a4776142e086c97581",
   "e5d431036fddc147a594c93542a2921e",
   "ef5759ff92165c4e90015fe67846ec3b",
   "097e0986d8b306e495a9be667cdabc71",
   "3a76d7cce4e9ecdb4fe70737e7879960",
   "b0f66f48ec744bdf5328aa5b336ca88c",
   "07f2b0a9b704a628743082e0968f5cbc",
   "33d27b158761fd77f8548f1ce3ae1cb0",
   "2f43b42fd833d1e77420a8dae7419000",
   "b29e5ac6a193793001fa157625e88b9e",
   "0ac6e1505530a756a34808a362a2b6a9",
   "0f9693248cdcf99ce169c189f0d93a61",
   "6ffc1f0498e2ef6453f3176c7c457fab",
   "7b90ee6f8781d1bc4123617b145c4368",
   "640061103a186fd26f59746dd4d6de57",
   "e35b43c56e720a142f61a1a3da176c96",
   "d7c8e6530fa586d441e79b630e5d7ec3",
   "78f47abb6597e3867c7abb5f59abb8b0",
   "c1998857407a30636b74dd83e9fd99b7",
   "1ba5798afe8b4b9b50a92451638e4938",
   "6019af823cc745ff239519a0110097ed",
   "30115b9210703022991b1b6ea563b523",
   "7974463748638706c4ccb40ee8e0717b",
   "71f2f1609b5cc73741f9e07b05ab0e6c",
   "732477c7f5d4080670738ff6df6da214",
   "44fd51da968ba3e9826a7bfc01c5315b",
   "a5c83e9c609c7ba7ea08197f3a40884f",
   "9f510c9287290ff2ae0ca220016f6f7a",
   "a44fc18c480b10ed64ec11d21b2b3d43",
   "2e2c2c4d314a75eb8b8ef2bc1765ecac",
   "406b98dcbaa39ff2691d337b1e491fba",
   "0de20b93bb878d597e59213991465648",
   "2f43b42fd833d1e77420a8dae7419000",
   "7d03d983dcfc893b98847e1b9516b925",
   "ec8e9b6ea679ae678dce8a399fc78da4",
   "ca850f6053bc0b3a691856592cff9181"
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "number_of_pagebreaks": 3,
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
